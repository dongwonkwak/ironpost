//! JSON ë¡œê·¸ íŒŒì„œ
//!
//! êµ¬ì¡°í™”ëœ JSON í˜•ì‹ì˜ ë¡œê·¸ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤. í•„ë“œ ì´ë¦„ ë§¤í•‘ì„ í†µí•´
//! ë‹¤ì–‘í•œ JSON ë¡œê·¸ í˜•ì‹ì„ ì§€ì›í•©ë‹ˆë‹¤.
//!
//! # ì§€ì› í˜•ì‹
//! - í‰íƒ„(flat) JSON ê°ì²´
//! - ì¤‘ì²©(nested) JSON ê°ì²´ (dot notationìœ¼ë¡œ í•„ë“œ ì ‘ê·¼)
//!
//! # ì‚¬ìš© ì˜ˆì‹œ
//! ```ignore
//! use ironpost_log_pipeline::parser::JsonLogParser;
//! use ironpost_core::pipeline::LogParser;
//!
//! let parser = JsonLogParser::default();
//! let raw = br#"{"timestamp":"2024-01-15T12:00:00Z","host":"web-01","message":"request processed"}"#;
//! let entry = parser.parse(raw)?;
//! assert_eq!(entry.hostname, "web-01");
//! ```

use std::time::SystemTime;

use chrono::DateTime;
use ironpost_core::error::IronpostError;
use ironpost_core::pipeline::LogParser;
use ironpost_core::types::{LogEntry, Severity};

use crate::error::LogPipelineError;

/// JSON ë¡œê·¸ í•„ë“œ ë§¤í•‘ ì„¤ì •
///
/// JSON ë¡œê·¸ì˜ í•„ë“œ ì´ë¦„ì„ `LogEntry` í•„ë“œì— ë§¤í•‘í•©ë‹ˆë‹¤.
/// ë‹¤ì–‘í•œ ë¡œê·¸ ë¼ì´ë¸ŒëŸ¬ë¦¬(serde_json tracing, bunyan, pino ë“±)ê°€
/// ì„œë¡œ ë‹¤ë¥¸ í•„ë“œ ì´ë¦„ì„ ì‚¬ìš©í•˜ë¯€ë¡œ, ë§¤í•‘ì„ í†µí•´ í†µí•©í•©ë‹ˆë‹¤.
#[derive(Debug, Clone)]
pub struct JsonFieldMapping {
    /// íƒ€ì„ìŠ¤íƒ¬í”„ í•„ë“œëª… (ê¸°ë³¸: "timestamp")
    pub timestamp_field: String,
    /// í˜¸ìŠ¤íŠ¸ëª… í•„ë“œëª… (ê¸°ë³¸: "host")
    pub hostname_field: String,
    /// í”„ë¡œì„¸ìŠ¤ëª… í•„ë“œëª… (ê¸°ë³¸: "process")
    pub process_field: String,
    /// ë©”ì‹œì§€ í•„ë“œëª… (ê¸°ë³¸: "message")
    pub message_field: String,
    /// ì‹¬ê°ë„ í•„ë“œëª… (ê¸°ë³¸: "level")
    pub severity_field: String,
}

impl Default for JsonFieldMapping {
    fn default() -> Self {
        Self {
            timestamp_field: "timestamp".to_owned(),
            hostname_field: "host".to_owned(),
            process_field: "process".to_owned(),
            message_field: "message".to_owned(),
            severity_field: "level".to_owned(),
        }
    }
}

/// JSON ë¡œê·¸ íŒŒì„œ
///
/// êµ¬ì¡°í™”ëœ JSON ë¡œê·¸ë¥¼ `LogEntry`ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
/// [`JsonFieldMapping`]ì„ í†µí•´ ë‹¤ì–‘í•œ JSON ë¡œê·¸ í˜•ì‹ì„ ì§€ì›í•©ë‹ˆë‹¤.
pub struct JsonLogParser {
    /// í•„ë“œ ë§¤í•‘ ì„¤ì •
    mapping: JsonFieldMapping,
    /// ìµœëŒ€ í—ˆìš© ì…ë ¥ í¬ê¸° (ë°”ì´íŠ¸)
    max_input_size: usize,
}

impl JsonLogParser {
    /// ì»¤ìŠ¤í…€ í•„ë“œ ë§¤í•‘ìœ¼ë¡œ ìƒˆ íŒŒì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    pub fn new(mapping: JsonFieldMapping) -> Self {
        Self {
            mapping,
            max_input_size: 1024 * 1024, // 1MB
        }
    }

    /// ìµœëŒ€ ì…ë ¥ í¬ê¸°ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
    pub fn with_max_input_size(mut self, size: usize) -> Self {
        self.max_input_size = size;
        self
    }

    /// JSON ê°ì²´ì—ì„œ ë¬¸ìì—´ í•„ë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    ///
    /// dot notationì„ ì§€ì›í•©ë‹ˆë‹¤ (ì˜ˆ: "metadata.host").
    fn extract_string(value: &serde_json::Value, field: &str) -> Option<String> {
        // dot notation ì²˜ë¦¬
        let parts: Vec<&str> = field.split('.').collect();
        let mut current = value;

        for part in &parts {
            current = current.get(*part)?;
        }

        match current {
            serde_json::Value::String(s) => Some(s.clone()),
            serde_json::Value::Number(n) => Some(n.to_string()),
            serde_json::Value::Bool(b) => Some(b.to_string()),
            _ => None,
        }
    }

    /// JSON ë¡œê·¸ ë ˆë²¨ ë¬¸ìì—´ì„ Severityë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    fn level_to_severity(level: &str) -> Severity {
        match level.to_lowercase().as_str() {
            "trace" | "debug" => Severity::Info,
            "info" | "information" => Severity::Info,
            "warn" | "warning" => Severity::Low,
            "error" | "err" => Severity::Medium,
            "fatal" | "critical" | "crit" | "emergency" | "emerg" => Severity::High,
            _ => Severity::Info,
        }
    }

    /// JSON ë°”ì´íŠ¸ë¥¼ íŒŒì‹±í•˜ì—¬ `LogEntry`ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    fn parse_json(&self, raw: &[u8]) -> Result<LogEntry, LogPipelineError> {
        if raw.len() > self.max_input_size {
            return Err(LogPipelineError::Parse {
                format: "json".to_owned(),
                offset: 0,
                reason: format!(
                    "input too large: {} bytes (max: {})",
                    raw.len(),
                    self.max_input_size
                ),
            });
        }

        let value: serde_json::Value =
            serde_json::from_slice(raw).map_err(|e| LogPipelineError::Parse {
                format: "json".to_owned(),
                offset: e.column(),
                reason: e.to_string(),
            })?;

        // ìµœìƒìœ„ê°€ JSON ê°ì²´ì—¬ì•¼ í•©ë‹ˆë‹¤
        if !value.is_object() {
            return Err(LogPipelineError::Parse {
                format: "json".to_owned(),
                offset: 0,
                reason: "expected JSON object at top level".to_owned(),
            });
        }

        let timestamp_str = Self::extract_string(&value, &self.mapping.timestamp_field);
        let timestamp = if let Some(ts) = timestamp_str {
            Self::parse_timestamp(&ts).unwrap_or_else(|_| SystemTime::now())
        } else {
            SystemTime::now()
        };

        let hostname =
            Self::extract_string(&value, &self.mapping.hostname_field).unwrap_or_default();
        let process = Self::extract_string(&value, &self.mapping.process_field).unwrap_or_default();
        let message = Self::extract_string(&value, &self.mapping.message_field).unwrap_or_default();
        let severity_str =
            Self::extract_string(&value, &self.mapping.severity_field).unwrap_or_default();
        let severity = Self::level_to_severity(&severity_str);

        // ë§¤í•‘ëœ í•„ë“œ ì´ì™¸ì˜ ëª¨ë“  í•„ë“œë¥¼ ì¶”ê°€ í•„ë“œë¡œ ìˆ˜ì§‘
        let known_fields = [
            &self.mapping.timestamp_field,
            &self.mapping.hostname_field,
            &self.mapping.process_field,
            &self.mapping.message_field,
            &self.mapping.severity_field,
        ];

        let fields: Vec<(String, String)> = Self::flatten_object(&value, "", &known_fields);

        Ok(LogEntry {
            source: "json".to_owned(),
            timestamp,
            hostname,
            process,
            message,
            severity,
            fields,
        })
    }

    /// JSON ê°ì²´ë¥¼ í‰íƒ„í™”í•˜ì—¬ dot notation í•„ë“œ ëª©ë¡ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    ///
    /// ë§¤í•‘ëœ í•„ë“œëŠ” ì œì™¸í•©ë‹ˆë‹¤.
    fn flatten_object(
        value: &serde_json::Value,
        prefix: &str,
        exclude: &[&String],
    ) -> Vec<(String, String)> {
        Self::flatten_object_impl(value, prefix, exclude, 0)
    }

    /// JSON ê°ì²´ í‰íƒ„í™” ë‚´ë¶€ êµ¬í˜„ (ì¬ê·€ ê¹Šì´ ì œí•œ í¬í•¨)
    fn flatten_object_impl(
        value: &serde_json::Value,
        prefix: &str,
        exclude: &[&String],
        depth: usize,
    ) -> Vec<(String, String)> {
        const MAX_NESTING_DEPTH: usize = 32;

        if depth > MAX_NESTING_DEPTH {
            tracing::warn!(
                "JSON nesting depth exceeds limit ({}), truncating",
                MAX_NESTING_DEPTH
            );
            return vec![];
        }

        let mut fields = Vec::new();

        if let Some(obj) = value.as_object() {
            for (key, val) in obj {
                let field_name = if prefix.is_empty() {
                    key.clone()
                } else {
                    format!("{}.{}", prefix, key)
                };

                // ì œì™¸ ëª©ë¡ì— ìˆëŠ” ìµœìƒìœ„ í•„ë“œëŠ” ìŠ¤í‚µ
                if prefix.is_empty() && exclude.contains(&key) {
                    continue;
                }

                match val {
                    serde_json::Value::Object(_) => {
                        // ì¬ê·€ì ìœ¼ë¡œ ì¤‘ì²© ê°ì²´ í‰íƒ„í™” (ê¹Šì´ ì œí•œ)
                        fields.extend(Self::flatten_object_impl(val, &field_name, &[], depth + 1));
                    }
                    serde_json::Value::Array(arr) => {
                        // ë°°ì—´ì€ JSON ë¬¸ìì—´ë¡œ ì§ë ¬í™”
                        if let Ok(s) = serde_json::to_string(arr) {
                            fields.push((field_name, s));
                        }
                    }
                    serde_json::Value::Null => {
                        // null ê°’ì€ ìŠ¤í‚µ
                    }
                    serde_json::Value::String(s) => {
                        fields.push((field_name, s.clone()));
                    }
                    serde_json::Value::Number(n) => {
                        fields.push((field_name, n.to_string()));
                    }
                    serde_json::Value::Bool(b) => {
                        fields.push((field_name, b.to_string()));
                    }
                }
            }
        }

        fields
    }

    /// íƒ€ì„ìŠ¤íƒ¬í”„ ë¬¸ìì—´ì„ íŒŒì‹±í•©ë‹ˆë‹¤.
    ///
    /// ì§€ì› í˜•ì‹:
    /// - RFC 3339 (ISO 8601): `2024-01-15T12:00:00Z`
    /// - Unix timestamp (ì´ˆ): `1705320000`
    /// - Unix timestamp (ë°€ë¦¬ì´ˆ): `1705320000000`
    fn parse_timestamp(timestamp: &str) -> Result<SystemTime, LogPipelineError> {
        // RFC 3339 ì‹œë„
        if let Ok(dt) = DateTime::parse_from_rfc3339(timestamp) {
            return Ok(SystemTime::from(dt));
        }

        // Unix timestamp (ì´ˆ ë˜ëŠ” ë°€ë¦¬ì´ˆ) ì‹œë„
        if let Ok(ts_num) = timestamp.parse::<i64>() {
            // ë°€ë¦¬ì´ˆì¸ì§€ ì´ˆì¸ì§€ íŒë‹¨ (10ìë¦¬ = ì´ˆ, 13ìë¦¬ = ë°€ë¦¬ì´ˆ)
            let ts_secs = if ts_num > 9_999_999_999 {
                // ë°€ë¦¬ì´ˆ
                ts_num / 1000
            } else {
                // ì´ˆ
                ts_num
            };

            if let Some(dt) = DateTime::from_timestamp(ts_secs, 0) {
                return Ok(SystemTime::from(dt));
            }
        }

        Err(LogPipelineError::Parse {
            format: "json".to_owned(),
            offset: 0,
            reason: format!("invalid timestamp format: '{}'", timestamp),
        })
    }
}

impl Default for JsonLogParser {
    fn default() -> Self {
        Self::new(JsonFieldMapping::default())
    }
}

impl LogParser for JsonLogParser {
    fn format_name(&self) -> &str {
        "json"
    }

    fn parse(&self, raw: &[u8]) -> Result<LogEntry, IronpostError> {
        self.parse_json(raw).map_err(IronpostError::from)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn format_name_is_json() {
        let parser = JsonLogParser::default();
        assert_eq!(parser.format_name(), "json");
    }

    #[test]
    fn parse_basic_json() {
        let parser = JsonLogParser::default();
        let raw =
            br#"{"host":"web-01","process":"nginx","message":"GET /index.html","level":"info"}"#;
        let entry = parser.parse(raw).unwrap();
        assert_eq!(entry.hostname, "web-01");
        assert_eq!(entry.process, "nginx");
        assert_eq!(entry.message, "GET /index.html");
        assert_eq!(entry.severity, Severity::Info);
    }

    #[test]
    fn parse_json_with_extra_fields() {
        let parser = JsonLogParser::default();
        let raw = br#"{"host":"web-01","message":"test","request_id":"abc-123","status":200}"#;
        let entry = parser.parse(raw).unwrap();
        assert!(!entry.fields.is_empty());
        assert!(entry.fields.iter().any(|(k, _)| k == "request_id"));
    }

    #[test]
    fn parse_non_object_fails() {
        let parser = JsonLogParser::default();
        let raw = br#"["not","an","object"]"#;
        assert!(parser.parse(raw).is_err());
    }

    #[test]
    fn parse_invalid_json_fails() {
        let parser = JsonLogParser::default();
        assert!(parser.parse(b"not json at all").is_err());
    }

    #[test]
    fn level_to_severity_mapping() {
        assert_eq!(JsonLogParser::level_to_severity("info"), Severity::Info);
        assert_eq!(JsonLogParser::level_to_severity("warn"), Severity::Low);
        assert_eq!(JsonLogParser::level_to_severity("ERROR"), Severity::Medium);
        assert_eq!(JsonLogParser::level_to_severity("FATAL"), Severity::High);
        assert_eq!(JsonLogParser::level_to_severity("unknown"), Severity::Info);
    }

    #[test]
    fn custom_field_mapping() {
        let mapping = JsonFieldMapping {
            hostname_field: "server".to_owned(),
            message_field: "msg".to_owned(),
            severity_field: "severity".to_owned(),
            ..Default::default()
        };
        let parser = JsonLogParser::new(mapping);
        let raw = br#"{"server":"db-01","msg":"query slow","severity":"warn"}"#;
        let entry = parser.parse(raw).unwrap();
        assert_eq!(entry.hostname, "db-01");
        assert_eq!(entry.message, "query slow");
    }

    #[test]
    fn extract_nested_field() {
        let value: serde_json::Value =
            serde_json::from_str(r#"{"metadata":{"host":"nested-host"},"message":"test"}"#)
                .unwrap();
        let result = JsonLogParser::extract_string(&value, "metadata.host");
        assert_eq!(result, Some("nested-host".to_owned()));
    }

    #[test]
    fn parse_too_large_input_fails() {
        let parser = JsonLogParser::default().with_max_input_size(10);
        let raw = br#"{"message":"this is way too long for the limit"}"#;
        assert!(parser.parse_json(raw).is_err());
    }

    #[test]
    fn parse_timestamp_rfc3339() {
        let ts = JsonLogParser::parse_timestamp("2024-01-15T12:00:00Z").unwrap();
        assert!(ts > SystemTime::UNIX_EPOCH);
    }

    #[test]
    fn parse_timestamp_unix_seconds() {
        let ts = JsonLogParser::parse_timestamp("1705320000").unwrap();
        assert!(ts > SystemTime::UNIX_EPOCH);
    }

    #[test]
    fn parse_timestamp_unix_milliseconds() {
        let ts = JsonLogParser::parse_timestamp("1705320000000").unwrap();
        assert!(ts > SystemTime::UNIX_EPOCH);
    }

    #[test]
    fn parse_timestamp_invalid() {
        let result = JsonLogParser::parse_timestamp("not-a-timestamp");
        assert!(result.is_err());
    }

    #[test]
    fn parse_json_with_timestamp() {
        let parser = JsonLogParser::default();
        let raw = br#"{"timestamp":"2024-01-15T12:00:00Z","host":"web-01","message":"test"}"#;
        let entry = parser.parse(raw).unwrap();
        assert!(entry.timestamp > SystemTime::UNIX_EPOCH);
    }

    #[test]
    fn parse_json_with_unix_timestamp() {
        let parser = JsonLogParser::default();
        let raw = br#"{"timestamp":"1705320000","host":"web-01","message":"test"}"#;
        let entry = parser.parse(raw).unwrap();
        assert!(entry.timestamp > SystemTime::UNIX_EPOCH);
    }

    #[test]
    fn flatten_nested_object() {
        let value: serde_json::Value =
            serde_json::from_str(r#"{"top":"value","nested":{"field1":"a","field2":"b"}}"#)
                .unwrap();
        let fields = JsonLogParser::flatten_object(&value, "", &[]);
        assert!(fields.iter().any(|(k, v)| k == "top" && v == "value"));
        assert!(fields.iter().any(|(k, v)| k == "nested.field1" && v == "a"));
        assert!(fields.iter().any(|(k, v)| k == "nested.field2" && v == "b"));
    }

    #[test]
    fn flatten_deeply_nested() {
        let value: serde_json::Value = serde_json::from_str(r#"{"a":{"b":{"c":"deep"}}}"#).unwrap();
        let fields = JsonLogParser::flatten_object(&value, "", &[]);
        assert!(fields.iter().any(|(k, v)| k == "a.b.c" && v == "deep"));
    }

    #[test]
    fn flatten_with_array() {
        let value: serde_json::Value =
            serde_json::from_str(r#"{"items":[1,2,3],"name":"test"}"#).unwrap();
        let fields = JsonLogParser::flatten_object(&value, "", &[]);
        assert!(fields.iter().any(|(k, _)| k == "items"));
        assert!(fields.iter().any(|(k, v)| k == "name" && v == "test"));
    }

    #[test]
    fn flatten_excludes_known_fields() {
        let value: serde_json::Value =
            serde_json::from_str(r#"{"host":"excluded","custom":"included"}"#).unwrap();
        let exclude = ["host".to_owned()];
        let exclude_refs: Vec<&String> = exclude.iter().collect();
        let fields = JsonLogParser::flatten_object(&value, "", &exclude_refs);
        assert!(!fields.iter().any(|(k, _)| k == "host"));
        assert!(fields.iter().any(|(k, _)| k == "custom"));
    }

    #[test]
    fn parse_json_with_null_values() {
        let parser = JsonLogParser::default();
        let raw = br#"{"host":"web-01","message":"test","null_field":null}"#;
        let entry = parser.parse(raw).unwrap();
        // null í•„ë“œëŠ” ì œì™¸ë˜ì–´ì•¼ í•¨
        assert!(!entry.fields.iter().any(|(k, _)| k == "null_field"));
    }

    #[test]
    fn parse_json_with_number_field() {
        let parser = JsonLogParser::default();
        let raw = br#"{"host":"web-01","message":"test","count":42,"ratio":3.14}"#;
        let entry = parser.parse(raw).unwrap();
        assert!(entry.fields.iter().any(|(k, v)| k == "count" && v == "42"));
        assert!(
            entry
                .fields
                .iter()
                .any(|(k, v)| k == "ratio" && v == "3.14")
        );
    }

    #[test]
    fn parse_json_with_bool_field() {
        let parser = JsonLogParser::default();
        let raw = br#"{"host":"web-01","message":"test","active":true}"#;
        let entry = parser.parse(raw).unwrap();
        assert!(
            entry
                .fields
                .iter()
                .any(|(k, v)| k == "active" && v == "true")
        );
    }

    // === Edge Case Tests ===

    #[test]
    fn parse_empty_json_object() {
        let parser = JsonLogParser::default();
        let result = parser.parse(b"{}");
        // Should have default values for required fields
        assert!(result.is_ok());
    }

    #[test]
    fn parse_empty_input() {
        let parser = JsonLogParser::default();
        let result = parser.parse(b"");
        assert!(result.is_err());
    }

    #[test]
    fn parse_only_whitespace() {
        let parser = JsonLogParser::default();
        let result = parser.parse(b"   \t\n   ");
        assert!(result.is_err());
    }

    #[test]
    fn parse_truncated_json() {
        let parser = JsonLogParser::default();
        let result = parser.parse(br#"{"host":"web-01","message":"test"#);
        assert!(result.is_err());
    }

    #[test]
    fn parse_json_with_trailing_comma() {
        let parser = JsonLogParser::default();
        let result = parser.parse(br#"{"host":"web-01","message":"test",}"#);
        // JSON spec doesn't allow trailing commas
        assert!(result.is_err());
    }

    #[test]
    fn parse_json_with_comments() {
        let parser = JsonLogParser::default();
        let result = parser.parse(br#"{"host":"web-01"/* comment */,"message":"test"}"#);
        // Standard JSON doesn't support comments
        assert!(result.is_err());
    }

    #[test]
    fn parse_json_with_single_quotes() {
        let parser = JsonLogParser::default();
        let result = parser.parse(b"{'host':'web-01','message':'test'}");
        // JSON requires double quotes
        assert!(result.is_err());
    }

    #[test]
    fn parse_extremely_nested_json() {
        let parser = JsonLogParser::default();
        let mut nested = String::from(r#"{"message":"test","host":"web-01","level":"info""#);
        for i in 0..100 {
            nested.push_str(&format!(r#","nested{}":{{}}"#, i));
        }
        // Close main object brace
        nested.push('}');
        let result = parser.parse(nested.as_bytes());
        // Very nested JSON might fail to parse or succeed depending on limits
        assert!(result.is_ok() || result.is_err());
    }

    #[test]
    fn parse_json_with_very_long_string() {
        let parser = JsonLogParser::default();
        let long_msg = "m".repeat(100000);
        let raw = format!(r#"{{"host":"web-01","message":"{}"}}"#, long_msg);
        let result = parser.parse_json(raw.as_bytes());
        if let Ok(entry) = result {
            assert_eq!(entry.message.len(), 100000);
        }
    }

    #[test]
    fn parse_json_with_unicode_escape() {
        let parser = JsonLogParser::default();
        let raw = br#"{"host":"web-01","message":"Hello \u4e16\u754c"}"#;
        let result = parser.parse(raw);
        assert!(result.is_ok());
        if let Ok(entry) = result {
            assert!(entry.message.contains("ä¸–ç•Œ"));
        }
    }

    #[test]
    fn parse_json_with_escaped_quotes() {
        let parser = JsonLogParser::default();
        let raw = br#"{"host":"web-01","message":"He said \"hello\""}"#;
        let result = parser.parse(raw);
        assert!(result.is_ok());
        if let Ok(entry) = result {
            assert!(entry.message.contains('"'));
        }
    }

    #[test]
    fn parse_json_with_escaped_backslash() {
        let parser = JsonLogParser::default();
        let raw = br#"{"host":"web-01","message":"path\\to\\file"}"#;
        let result = parser.parse(raw);
        assert!(result.is_ok());
    }

    #[test]
    fn parse_json_with_control_chars() {
        let parser = JsonLogParser::default();
        let raw = br#"{"host":"web-01","message":"line1\nline2\ttab"}"#;
        let result = parser.parse(raw);
        assert!(result.is_ok());
    }

    #[test]
    fn parse_json_array_as_root() {
        let parser = JsonLogParser::default();
        let result = parser.parse(br#"[{"host":"web-01"},{"host":"web-02"}]"#);
        assert!(result.is_err());
    }

    #[test]
    fn parse_json_string_as_root() {
        let parser = JsonLogParser::default();
        let result = parser.parse(br#""just a string""#);
        assert!(result.is_err());
    }

    #[test]
    fn parse_json_number_as_root() {
        let parser = JsonLogParser::default();
        let result = parser.parse(b"42");
        assert!(result.is_err());
    }

    #[test]
    fn parse_json_with_duplicate_keys() {
        let parser = JsonLogParser::default();
        let raw = br#"{"host":"first","host":"second","message":"test"}"#;
        let result = parser.parse(raw);
        // serde_json uses last value for duplicate keys
        assert!(result.is_ok());
    }

    #[test]
    fn parse_json_with_very_large_number() {
        let parser = JsonLogParser::default();
        let raw = br#"{"host":"web-01","message":"test","big":99999999999999999999}"#;
        let result = parser.parse(raw);
        // Should handle large numbers
        assert!(result.is_ok());
    }

    #[test]
    fn parse_json_with_negative_number() {
        let parser = JsonLogParser::default();
        let raw = br#"{"host":"web-01","message":"test","temp":-273.15}"#;
        let result = parser.parse(raw);
        assert!(result.is_ok());
    }

    #[test]
    fn parse_json_with_scientific_notation() {
        let parser = JsonLogParser::default();
        let raw = br#"{"host":"web-01","message":"test","value":1.23e10}"#;
        let result = parser.parse(raw);
        assert!(result.is_ok());
    }

    #[test]
    fn parse_json_with_empty_string_values() {
        let parser = JsonLogParser::default();
        let raw = br#"{"host":"","message":"","process":""}"#;
        let result = parser.parse(raw);
        assert!(result.is_ok());
    }

    #[test]
    fn parse_json_with_missing_message_field() {
        let parser = JsonLogParser::default();
        let raw = br#"{"host":"web-01","process":"nginx"}"#;
        let result = parser.parse(raw);
        assert!(result.is_ok());
        // Should use empty or default message
    }

    #[test]
    fn parse_timestamp_negative_unix() {
        let result = JsonLogParser::parse_timestamp("-1");
        // Negative timestamps (before epoch) might not be supported
        assert!(result.is_err() || result.is_ok());
    }

    #[test]
    fn parse_timestamp_far_future() {
        let result = JsonLogParser::parse_timestamp("9999999999");
        // Far future timestamps should work
        assert!(result.is_ok());
    }

    #[test]
    fn parse_timestamp_zero() {
        let result = JsonLogParser::parse_timestamp("0");
        // Unix epoch
        assert!(result.is_ok());
    }

    #[test]
    fn parse_timestamp_with_fractional_seconds() {
        let result = JsonLogParser::parse_timestamp("2024-01-15T12:00:00.123456Z");
        assert!(result.is_ok());
    }

    #[test]
    fn parse_timestamp_with_timezone_offset() {
        let result = JsonLogParser::parse_timestamp("2024-01-15T12:00:00+09:00");
        assert!(result.is_ok());
    }

    #[test]
    fn extract_nonexistent_nested_field() {
        let value: serde_json::Value =
            serde_json::from_str(r#"{"metadata":{"host":"test"}}"#).unwrap();
        let result = JsonLogParser::extract_string(&value, "metadata.nonexistent");
        assert_eq!(result, None);
    }

    #[test]
    fn extract_deeply_nested_field() {
        let value: serde_json::Value =
            serde_json::from_str(r#"{"a":{"b":{"c":{"d":"deep"}}}}"#).unwrap();
        let result = JsonLogParser::extract_string(&value, "a.b.c.d");
        assert_eq!(result, Some("deep".to_owned()));
    }

    #[test]
    fn extract_from_array_fails_gracefully() {
        let value: serde_json::Value = serde_json::from_str(r#"{"items":[1,2,3]}"#).unwrap();
        let result = JsonLogParser::extract_string(&value, "items.0");
        // Array indexing not supported in dot notation
        assert_eq!(result, None);
    }

    #[test]
    fn parse_json_with_max_depth() {
        let parser = JsonLogParser::default();
        let mut json = String::from(r#"{"host":"web-01","message":"test","deep":"#);
        for _ in 0..1000 {
            json.push_str(r#"{"a":"#);
        }
        json.push_str(r#""value""#);
        for _ in 0..1000 {
            json.push('}');
        }
        json.push('}');
        let result = parser.parse(json.as_bytes());
        // Very deep nesting might cause stack overflow or be rejected
        let _ = result;
    }

    #[test]
    fn parse_json_with_special_chars_in_keys() {
        let parser = JsonLogParser::default();
        let raw = br#"{"host":"web-01","message":"test","special-key_123":"value"}"#;
        let result = parser.parse(raw);
        assert!(result.is_ok());
    }

    #[test]
    fn parse_json_with_emoji_in_values() {
        let parser = JsonLogParser::default();
        let raw = r#"{"host":"web-01","message":"Hello ğŸŒ World ğŸš€"}"#;
        let result = parser.parse(raw.as_bytes());
        assert!(result.is_ok());
        if let Ok(entry) = result {
            assert!(entry.message.contains("ğŸŒ"));
            assert!(entry.message.contains("ğŸš€"));
        }
    }

    #[test]
    fn parse_non_utf8_bytes() {
        let parser = JsonLogParser::default();
        let mut raw = Vec::from(br#"{"host":"web-01","message":"test"#);
        raw.extend_from_slice(&[0xFF, 0xFE]); // Invalid UTF-8
        raw.extend_from_slice(br#""}"#);
        let result = parser.parse(&raw);
        // Should fail on invalid UTF-8
        assert!(result.is_err());
    }

    // Property-based tests
    #[cfg(test)]
    mod proptests {
        use super::*;
        use proptest::prelude::*;

        proptest! {
            #[test]
            fn parse_arbitrary_bytes_does_not_panic(bytes in prop::collection::vec(any::<u8>(), 0..1000)) {
                let parser = JsonLogParser::default();
                let _ = parser.parse(&bytes);
                // Should never panic
            }

            #[test]
            fn parse_valid_json_object_does_not_panic(
                host in "[a-zA-Z0-9-]{1,50}",
                msg in "[a-zA-Z0-9 ]{1,100}"
            ) {
                let parser = JsonLogParser::default();
                let raw = format!(r#"{{"host":"{}","message":"{}"}}"#, host, msg);
                let _ = parser.parse(raw.as_bytes());
                // Should not panic
            }

            #[test]
            fn parse_arbitrary_json_string_length(msg_len in 0usize..10000) {
                let parser = JsonLogParser::default();
                let msg = "x".repeat(msg_len);
                let raw = format!(r#"{{"host":"web-01","message":"{}"}}"#, msg);
                let result = parser.parse(raw.as_bytes());
                if result.is_ok() {
                    prop_assert_eq!(result.unwrap().message.len(), msg_len);
                }
            }
        }
    }
}
